{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Implementing_sentiment_analysis_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhash505/NLP_code/blob/main/2_Implementing_sentiment_analysis_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zycNwG-gDCpe"
      },
      "source": [
        "# For Handling Data\n",
        "import pandas as pd\n",
        "\n",
        "# increase the output column width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# For numerical computing\n",
        "import numpy as np\n",
        "\n",
        "# Library for pattern matching\n",
        "import re\n",
        "\n",
        "# for NLP related tasks\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm',disable=[\"tagger\", \"parser\",\"ner\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4t1kXzZ9Pr"
      },
      "source": [
        "<font size=5>**Steps to Follow**</font>\n",
        "1. Loading and Exploring Data\n",
        "2. Text Cleaning\n",
        "3. Data Preparation\n",
        "    1. Label Encoding\n",
        "    2. Split Data\n",
        "    3. Feature Engineering using TF-IDF\n",
        "4. Model Building\n",
        "    1. Naive Bayes\n",
        "    2. Logistic Regression\n",
        "    3. Model Building Summary\n",
        "5. Final Sentiment Analysis Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8rRv9giYX2J"
      },
      "source": [
        "# Loading and Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NL8QCLAzKhV",
        "outputId": "b1cc25c0-2a6f-4381-9c56-f637b1e97105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsmE1o_L8sKh",
        "outputId": "286dc1fa-cf86-4509-88ea-4d98dbac8db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "# read CSV file\n",
        "df = pd.read_csv('/content/drive/My Drive/Tweets.csv')\n",
        "\n",
        "#shape of the dataframe\n",
        "print('Shape=>',df.shape)\n",
        "\n",
        "# print first 5 rows\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape=> (14640, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW6fROJOBHsB",
        "outputId": "735aeb71-4fff-4032-fd2a-50faf934ad7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Some sample tweets\n",
        "df['text'].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6488                                                                                              @SouthwestAir El Paso deals....May‚ù§‚ù§‚ù§üòçüåè\n",
              "1140                                                       @united\\nYou really know how to piss people off. Your Farelock option is fake!\n",
              "1676          @united used to (still do?) let you listen to flight radio...I often did...interesting to me #TCMParty #CE3K #31DaysOfOscar\n",
              "1228    @united 2nd flight in two weeks that you have lost my bag!  Taking my 1K status to @AmericanAir #neveragain #WORSTCUSTOMERSERVICE\n",
              "3811         @united Why does it take 4-6 weeks for a new MileagePlus Premier card to be sent out? #stillwaiting #doesntfeellikestatusyet\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHP8lW2nBNtx",
        "outputId": "625cff3c-ac1c-4630-98bf-b239da5ca2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V48ABFS2BamQ",
        "outputId": "2730e3f2-f44b-4373-c698-f74b0f292532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# class distribution in percentage\n",
        "df['airline_sentiment'].value_counts(normalize = True)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    62.691257\n",
              "neutral     21.168033\n",
              "positive    16.140710\n",
              "Name: airline_sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryGX7a8YC7KP"
      },
      "source": [
        "# Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpyaEZ7ZCbi4"
      },
      "source": [
        "#define a function for text cleaning\n",
        "def text_cleaner(text):\n",
        "  \n",
        "  #remove user mentions\n",
        "  text = re.sub(r'@[A-Za-z0-9]+','',text)           \n",
        "  \n",
        "  #remove hashtags\n",
        "  #text = re.sub(r'#[A-Za-z0-9]+','',text)         \n",
        "  \n",
        "  #remove links\n",
        "  text = re.sub(r'http\\S+', '', text)  \n",
        "\n",
        "  #convering text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  # fetch only words\n",
        "  text = re.sub(\"[^a-z]+\", \" \", text)\n",
        "\n",
        "  # removing extra spaces\n",
        "  text=re.sub(\"[\\s]+\",\" \",text)\n",
        "  \n",
        "  # creating doc object\n",
        "  doc=nlp(text)\n",
        "\n",
        "  # remove stopwords and lemmatize the text\n",
        "  tokens=[token.lemma_ for token in doc if(token.is_stop==False)]\n",
        "  \n",
        "  #join tokens by space\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwFRBdfyEDR3"
      },
      "source": [
        "# perform text cleaning\n",
        "df['clean_text']= df['text'].apply(text_cleaner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRZPKAsREL2o"
      },
      "source": [
        "# save cleaned text and labels to a variable\n",
        "text   = df['clean_text'].values\n",
        "labels = df['airline_sentiment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFmdm52REduh",
        "outputId": "e16f9396-cf73-4157-ab6d-1097dba5ed43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Sample cleaned text\n",
        "text[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['  say', '  plus have add commercial experience tacky',\n",
              "       '  didn t today mean need trip',\n",
              "       '  s aggressive blast obnoxious entertainment guest face amp little recourse',\n",
              "       '  s big bad thing',\n",
              "       '  seriously pay flight seat didn t play s bad thing fly va',\n",
              "       '  yes nearly time fly vx ear worm win t away',\n",
              "       '  miss prime opportunity man hat parody', '  didn t have',\n",
              "       '  amaze arrive hour early good'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsxoIoXBEh5b",
        "outputId": "e09201a1-8d2c-4320-e77e-2a360e90335d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Sample labels\n",
        "labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'positive', 'neutral', 'negative', 'negative',\n",
              "       'negative', 'positive', 'neutral', 'positive', 'positive'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI_ffjshaW-U"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baVcHgeJywP0"
      },
      "source": [
        "## Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TLWk1fCGVB_"
      },
      "source": [
        "#importing label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#define label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a numbers\n",
        "labels = le.fit_transform(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osgg4MrwGeZ8",
        "outputId": "853e9f2d-0414-41ec-bd23-4f2e275bf1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Sample labels\n",
        "labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, 0, 0, 0, 2, 1, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYQr5UOkvtD",
        "outputId": "f685cc59-52b9-4102-cff7-a36046fa419e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Meaning of each label\n",
        "le.inverse_transform([0,1,2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s1i7gduyyaB"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-8DreSYHQUM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting into train and validation set\n",
        "x_train,x_val,y_train,y_val=train_test_split(text, labels,stratify=labels, test_size=0.2, random_state=0,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5ag4mj1Ho2z",
        "outputId": "8727b06e-9169-4be4-f165-d683ea00ae22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('x_train:',x_train.shape,'y_train:',y_train.shape)\n",
        "print('x_val:',x_val.shape,'y_val:',y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train: (11712,) y_train: (11712,)\n",
            "x_val: (2928,) y_val: (2928,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yp5tJfiGKoi"
      },
      "source": [
        "## Feature Engineering using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ldb3a6-F4Yb"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nduH1hNrIsg3"
      },
      "source": [
        "# initialize TFIDF\n",
        "word_vectorizer = TfidfVectorizer(max_features=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MINBzLp-IvCw",
        "outputId": "c8290806-04d0-4437-81b8-9cd3c9f823db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Fitting Vectorizer on Train set\n",
        "word_vectorizer.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=1000,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zUWWtupIx1H",
        "outputId": "16a35dd2-bfe0-407c-a73c-91ca67166dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# create TF-IDF vectors for Train Set\n",
        "train_word_features = word_vectorizer.transform(x_train)\n",
        "train_word_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11712x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 71990 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NMDItaEJN-H",
        "outputId": "16401391-9583-4a0d-fcdd-aa4da1d23024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# create TF-IDF vectors for Validation Set\n",
        "val_word_features = word_vectorizer.transform(x_val)\n",
        "val_word_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2928x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 18214 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p4TbbuuJS7x"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa3PoKl6JmXl"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYhyxfldJRXQ"
      },
      "source": [
        "# Importing for modeling\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEdj-so1Jqip",
        "outputId": "313d0082-5ea0-4c9a-f647-6abadca5f9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Training model\n",
        "nb_model=MultinomialNB().fit(train_word_features,y_train)\n",
        "nb_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzMpj555J3ZM"
      },
      "source": [
        "# Make predictions for train set\n",
        "train_pred_nb=nb_model.predict(train_word_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IFgZ62jK15l",
        "outputId": "dcbdf0fc-e514-4e99-dc74-2f963d309ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_pred_nb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, ..., 2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exUyd3JZK3Ph",
        "outputId": "c492f4b8-6040-4393-c6f4-2fc1174a4005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluating on Training Set\n",
        "print(\"F1-score on Train Set:\",f1_score(y_train,train_pred_nb,average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score on Train Set: 0.7274362505640414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEiumjqnLah6",
        "outputId": "e246d20c-b436-4696-b4a5-6e3343bd49c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Make predictions for validation set\n",
        "val_pred_nb=nb_model.predict(val_word_features)\n",
        "\n",
        "# Evaluating on Validation Set\n",
        "print(\"F1-score on Validation Set:\",f1_score(y_val,val_pred_nb,average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score on Validation Set: 0.6791010943912907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI-VDut1NzHs"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttdTtqu4Np_s"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgnsHGc1N8_n",
        "outputId": "fa71cdad-bf69-440d-ef0b-e5c0b6457a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Training model\n",
        "lr_model=LogisticRegression().fit(train_word_features,y_train)\n",
        "lr_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKYJnI7tOCKz",
        "outputId": "0a563710-666d-4892-a213-86a38c1fc63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Make predictions for train set\n",
        "train_pred_lr=lr_model.predict(train_word_features)\n",
        "train_pred_nb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, ..., 2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeemBVUyOLTE",
        "outputId": "14a9df11-7d10-4c9d-9eb4-530a359d2261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluating on Training Set\n",
        "print(\"F1-score on Train Set:\",f1_score(y_train,train_pred_lr,average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score on Train Set: 0.8089316012430398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CF6IGU0OPu2",
        "outputId": "b472d2c9-37d4-4b85-b710-a66ecb7b3b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Make predictions for validation set\n",
        "val_pred_lr=lr_model.predict(val_word_features)\n",
        "\n",
        "# Evaluating on Validation Set\n",
        "print(\"F1-score on Validation Set:\",f1_score(y_val,val_pred_lr,average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score on Validation Set: 0.7598976736399601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0X3i_GYOXi1"
      },
      "source": [
        "## Model Building Summary\n",
        "|        Model        | Train Set | Validation Set |\n",
        "|:-------------------:|:---------:|:--------------:|\n",
        "|     Naive Bayes     |   0.7274  |     0.6791     |\n",
        "| Logistic Regression |   0.8089  |     0.7598     |\n",
        "\n",
        "It is evident from the results that Logistic Regression performs better than Naive Bayes on this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE937pt3Vkdh"
      },
      "source": [
        "# Final Sentiment Analysis Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlAQcqW7ObZd"
      },
      "source": [
        "def sentiment_analyzer(tweet):\n",
        "  # Cleaning Tweet\n",
        "  cleaned_tweet=text_cleaner(tweet)\n",
        "\n",
        "  # Feature Engineering\n",
        "  tweet_vector=word_vectorizer.transform([cleaned_tweet])\n",
        "\n",
        "  # Predicting Sentiment\n",
        "  label=lr_model.predict(tweet_vector)\n",
        "\n",
        "  return le.inverse_transform(np.array(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwiwbAuJYNW7"
      },
      "source": [
        "<font size=4>**Sample Tweet:**</font>\n",
        "<p>@USAirways flt 419. 2+ hrs Late Flight, baggage + 1 more hr. Now I see they delivered my suitcase wet inside &amp; out. #NotHappy</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIZwLDctZZm4",
        "outputId": "d9e34af4-e81e-4849-d931-e2df9d1cbe28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentiment_analyzer(\"@USAirways flt 419. 2+ hrs Late Flight, baggage + 1 more hr. Now I see they delivered my suitcase wet inside &amp; out. #NotHappy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRNn6Bvb30iX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}